{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe7176d-79f1-46dc-813a-3cdac34de946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90999997-19e8-496a-b1cf-63e2dd209a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97f5753-6cb6-4584-ada0-27e365d6ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatCohere(model='command-r-plus', temperature=0.2)\n",
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b560b18e-a436-4966-9a95-746b999f6d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "پیام خود را بنویسید ... (برای خروج 0 را بزنید)\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "while (True):\n",
    "    # Getting user message\n",
    "    user_message = input('پیام خود را بنویسید ... (برای خروج 0 را بزنید)\\n')\n",
    "\n",
    "    # Exit the loop if the user enters '0'\n",
    "    if (user_message == '0'):\n",
    "        break\n",
    "    else:\n",
    "        print('User:',user_message, '\\n')\n",
    "\n",
    "        history.add_user_message(user_message)\n",
    "\n",
    "        model_message = ''\n",
    "        print('AI: ', end='')\n",
    "        for chunk in chat_model.stream(history.messages):\n",
    "            model_message = model_message+ chunk.content\n",
    "            print(chunk.content, end=\"\",flush=True)\n",
    "        print('\\n')\n",
    "\n",
    "        history.add_ai_message(model_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f89c4-522d-4ab4-b1bd-a75159f49877",
   "metadata": {},
   "source": [
    "# Lecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dcfe09-b595-463a-825f-f8c878159204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95476ee1-76db-41ab-ba59-9014a6f70cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"تو یک مدل گفت‌وگو هستی که مانند دوست با کاربر صحبت می‌کنی.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae42359-1194-4652-a015-3f862c5184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a274fae9-4294-4592-92fd-df9b018f9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store the chat history for each session id\n",
    "store = {}\n",
    "\n",
    "# A function that returns the chat history for a given session id\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    # If the session id is not in the store dictionary\n",
    "    if session_id not in store:\n",
    "        # Create a new ChatMessageHistory object and add it to the store\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    # Return the message history for the session id\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f6c7c-338a-437a-a1a7-a307881a7e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b075156d-ee30-4b0a-890d-7cb81be5bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac84516d-8918-439c-8e84-4f57f7b4e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key = \"input\",\n",
    "    history_messages_key = \"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d38c4e-b832-42d0-ae67-a6496525271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "پیام خود را بنویسید ... (برای خروج 0 را بزنید)\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "while (True):\n",
    "\n",
    "    # Get user message\n",
    "    user_message = input('پیام خود را بنویسید ... (برای خروج 0 را بزنید)\\n')\n",
    "\n",
    "    # Exit the loop if the user enters '0'\n",
    "    if (user_message == '0'):\n",
    "        break\n",
    "    else:\n",
    "        print('User:', user_message, '\\n')\n",
    "\n",
    "        model_message = ''\n",
    "        print('AI: ', end='')\n",
    "        for chunk in with_message_history.stream({\"input\": user_message},\n",
    "                                                 {\"configurable\": {\"session_id\": \"1234\"}}):\n",
    "            model_message =  model_message + chunk.content\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d3def-1b80-40cc-9f8e-d5025758a176",
   "metadata": {},
   "source": [
    "# Lecture 3\n",
    "## Trimming Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25880c7d-25f3-44b5-87a1-1db2774fdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf9d72f-f19a-4e8d-826b-5f20f355964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(strategy=\"last\", max_tokens=2, token_counter=len)\n",
    "\n",
    "chain_with_trimming = (\n",
    "    # Replace the current chat_history with the trimmed chat history\n",
    "    RunnablePassthrough.assign(chat_history=itemgetter(\"chat_history\") | trimmer)\n",
    "    | chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ee6506-4e85-4adf-9003-9a4a75399aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain_with_trimming,\n",
    "    get_session_history,\n",
    "    input_messages_key = \"input\",\n",
    "    history_messages_key = \"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33714d5d-f3a8-40a3-bbfa-71e423158231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "پیام خود را بنویسید ... (برای خروج 0 را بزنید)\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "while (True):\n",
    "\n",
    "    # Get user message\n",
    "    user_message = input('پیام خود را بنویسید ... (برای خروج 0 را بزنید)\\n')\n",
    "\n",
    "    # Exit the loop if the user enters '0'\n",
    "    if (user_message == '0'):\n",
    "        break\n",
    "    else:\n",
    "        print('User:', user_message, '\\n')\n",
    "\n",
    "        model_message = ''\n",
    "        print('AI: ', end='')\n",
    "        for chunk in with_message_history.stream({\"input\": user_message},\n",
    "                                                 {\"configurable\": {\"session_id\": \"1234\"}}):\n",
    "            model_message =  model_message + chunk.content\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d37d02-c5bd-4e28-80b8-0e5266dadda3",
   "metadata": {},
   "source": [
    "# Lecture 4\n",
    "### Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c414a2-6894-481b-a0e5-545758609281",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"تو یک دستیار گفت‌وگو هستی. تمام سوالات را به بهترین شکل پاسخ بده. تاریخچه‌ی گفت‌وگو شامل خلاصه‌ای از مکالمه با کاربر تا این لحظه نیز در اختیارت قرار گرفته است.\",\n",
    "            # Or something like this in English: \"You are a helpful assistant. Answer all questions to the best of your ability. The provided chat history includes facts about the user you are speaking with.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91ef91d9-188d-4719-96ec-4a1565c606a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_history = ChatMessageHistory()\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb267540-95d0-486f-ae53-be77636436e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1765d69b-be96-4098-9d21-8a7e3990224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model_for_history = ChatCohere(model='command-r-plus', temprature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3437448e-2c39-41c5-900e-67cf774c3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_message_history.messages\n",
    "    \n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    \n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\", \"پیام‌های بالا را در یک پیام خلاصه‌شده فشرده کن. تا جایی که می‌تونی تمام جزئیات و اطلاعات خاص و مهم هر پیام رو در این خلاصه نگه دار\"\n",
    "                # Or something like this in English: \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Summarizing messages...\")\n",
    "\n",
    "    summarization_chain = summarization_prompt | chat_model_for_history\n",
    "\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    print(\"Finished! The summary message is:\", summary_message.content)\n",
    "\n",
    "    chat_message_history.clear()\n",
    "\n",
    "    chat_message_history.add_message(summary_message)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2bed7e7-8eda-40d0-83cc-506b41e4848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(chat_history=summarize_messages)\n",
    "    | with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ffe114b-e01d-4952-94a2-d895f55d387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing messages...\n",
      "Finished! The summary message is: دیبا با سلام و احوالپرسی شروع کرد و خودش را معرفی کرد. در پاسخ، شما خودتان را Command R+ معرفی کردید و ابراز کردید که یک دستیار گفت‌وگوی هوشمند هستید و آماده کمک کردن به دیبا هستید.\n",
      "سلام متین! خوشحالم که با شما آشنا می‌شوم. من Command R+ هستم، یک دستیار گفت‌وگوی هوشمند و پیشرفته. چطور می‌تونم کمکتون کنم؟\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"سلام چطوری؟ من متین هستم.\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f19d33-adf4-4f26-a4c6-c94b9d04257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing messages...\n",
      "Finished! The summary message is: دیبا و متین با سلام و احوالپرسی شروع کردند و خود را معرفی نمودند. Command R+، یک دستیار گفت‌وگوی هوشمند و پیشرفته، نیز خود را معرفی کرد و آمادگی خود را برای کمک به کاربران ابراز نمود.\n",
      "چرا برنامه‌نویس‌ها نمی‌تونن دوش بگیرن؟\n",
      "\n",
      "چون به جای SOAP از DOAP استفاده می‌کنن!\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"یک جوک خنده‌دار درباره‌ی برنامه‌نویسی میگی؟\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e328dd8-a384-4964-a799-11d5f20f4a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
